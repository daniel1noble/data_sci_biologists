---
title: "Meta-analysis: Multi-level models"
author: "<your name and u number>"
date: "`r Sys.Date()`"
output: 
  bookdown::html_document2:
    code_folding: show
    number_sections: no
    toc: yes
    toc_depth: 6
    toc_float: yes
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = FALSE, tidy = TRUE)
options(digits=2)
```

## **Load the necessary R Packages**

```{r loadpacks, message=FALSE, results='hide'}
# Install a load of packages that we'll use. I'll show you a shortcut that I love to use. Try using the p_load function in the "pacman" package. p_load will execute both the install.packages and library commands in one shot so they only need to be used once to install pacman itself.
#install.packages("pacman", repos = "http://cran.us.r-project.org")
library(pacman)

# Install bookdown for rendering because we'll need this. While we're at it, lets also install /load the tidyverse
p_load(bookdown, tidyverse, ggforce, GGally, flextable, latex2exp, png, magick, metafor, MASS) # basically just list all the packages you want here

```

## **Setting the scene: Meta-analysis of studies estimating the correlation between physiology and movement patterns**

Physiology is expected to drive movement, including short-term activity, exploration of unfamiliar environments, and larger scale dispersal which can influence species distributions in an environmentally sensitive manner. To test whether there is a relationship between physiology and movement pattern (separated as activity, exploration, and dispersal), [Wu & Seebacher 2022](https://doi.org/10.1038/s42003-022-03055-y) extracted correlations from the literature between common physiological traits (e.g., metabolic rate, hormone levels, body condition) and either activity, exploration, and dispersal at the individual level. 

Here, we will conduct a meta-analysis of correlations taken from the literature using the Zr effect size (see below and your readings). Throughout, there will be coding tasks for you to do so that you engage with key concepts and functions that will be useful for your assignment. 

## **Task 1: Understanding Sampling Variance for Zr**

In your readings for the week you would have been introduced to various types of effect size estimates (see Table 1). There we showed you what the sampling variance actually means and how the formulas are shortcuts to estimating sampling variance. Before embarking on the meta-analysis using Zr, your first task is to understand why the formula for Zr sampling variance does in fact estimate it's sampling variance correctly. 

Recall the formula for calculating correlation-based effect size estimates:

$$
Zr = \frac{1}{2}log \left( \frac{1+r}{1-r}\right)
$$
Here, r, is the correlation coefficient. The reason why we z-transform the correlation coefficient is because correlations range from -1 to 1. Since they are bounded, they are not normally distributed. Z-transformation will make the distribution of correlations normal to satisfy the assumptions of meta-analytic models. recall that the associated sampling variance calculation for Zr can be calculated as:

$$
v_{Zr} = \frac{1}{N - 3}
$$

Here, you will conduct a simple simulation to show the $v_{Zr}$ indeed is a good estimate of sampling error. Below we have provided code-chunks for you. Where it says "ADD YOUR CODE HERE" you should provide the necessary code to complete the task.

```{r}

# Lets set up the simulated experiment. We'll again conduct 10000 simulations, or experiments, where we sample 20 individuals from a population and measure 2 traits on those individuals that have a correlation of 0.70. 
     nsim = 10000
        n = 20
        r = 0.70
covMatrix = matrix(c(1, r, r, 1), nrow = 2, ncol = 2)

# Create an empty vector to store our simulated Zr values.
  Zr <- c()

# Run our simulation. Here, we need to estimate the correlation between two randomly drawn traits, convert this to Zr and store it.
 for(i in 1:nsim){
    sim_r <- MASS::mvrnorm(n = n, mu = c(0,0), Sigma = covMatrix)
      cor <- cor(sim_r)[1,2] #"ADD YOUR CODE HERE"
      Zr_tmp <- 0.5*log((1 + cor) / (1 - cor)) # "ADD YOUR CODE HERE"
      Zr <- c(Zr, Zr_tmp)
  }

```


In the code chunk below. Plot the sampling distribution of Zr values. Add the true mean and the sample mean to the plot as was done in the readings

```{r sampldistZr}

#"ADD YOUR CODE HERE"
# Now lets plot the sampling distribution. 
ggplot2::ggplot(tibble(Zr), aes(x = Zr)) + 
  geom_histogram(binwidth = 0.02) +
  geom_vline(xintercept = 0.5*log((1 + r) / (1 - r)), col = "red") +                     # Add the true mean in red
  geom_vline(xintercept = mean(Zr), col = "blue", linetype = 2) + # Add the mean of the means
  labs(x = "Z-transformed Correlation Coefficient (Zr)")
```

```{r}
# We know the 'true' values so we can use them to calculate what the sampling variance for this specific situation should be. 
     sv_Zr <- 1 / (n - 3) #"ADD YOUR CODE HERE"

# We just did a simple simulation of the situation where we only calculate the effect size statistic, now lets see what the sampling variance is of the Zr sampling distribution that we calculated.
samp_dist_Zr <- var(Zr) #"ADD YOUR CODE HERE"

# Again, let's create a table to contrast these a little more clearly
tab <- data.frame(Approach = c("Analytical", "Simulation"), `Sampling Variance` = c(sv_Zr,samp_dist_Zr), check.names = FALSE)
flextable(tab)
```


## **Task 2: Downloading and calculating Zr from the raw meta-analytic data**

Now that you understand Zr and it's sampling variance better, download the data using the code chunk below. The following code illustrates how to calculate the Fisher z-transformed effect size (Zr) and sampling variance (V_Zr).

```{r datadownload, message=FALSE}
# Download and clean data
zr_data <- read.csv("https://raw.githubusercontent.com/daniel1noble/meta-workshop/gh-pages/data/ind_disp_raw_data.csv") %>%
  dplyr::select(study_ID, taxa, species, trait, response, response_unit, disp_trait, disp_unit, corr_coeff, sample_size) %>%  # remove irrelevant columns for this tutorial
  mutate(obs = 1:n()) # Add this observation level variable. We'll explain later what it means.
```

Now that you have downloaded the data have a look at it, explore the data a little. The `corr_coeff` column is the correlation coefficient and the `sample_size` is the size of the sample used to estimate the correlation. The correlation coefficient itself is a unit less measure that captures both the strength and direction of relationship between two variables. The raw correlation coefficient ranges from -1 to 1. If a correlation is positive it indicates that, as the value of one variable increases so to does the value of the second variable. The magnitude of the value indicates how strong they co-vary. For example, a correlation of 1 indicates that variable 1 perfectly co-varies with variable 2. 

Other important variables in the dataset are `study_ID`, which is the identifier for the study the effect size (i.e., correlation) was extracted, and `species` which identifies the species the effect size was extracted for. 


```{r, exploredata}
# There's a bunch of free stuff they can do here. 
#Studies / taxa
std_taxa <- zr_data %>% group_by(taxa) %>% summarise(stdy = length(unique(study_ID)),
                                                     effects = n())
std_taxa %>% ggplot(aes(x = taxa, y = stdy)) + 
             geom_point(size = 6, aes(colour = effects)) + 
             labs(y = "Number of Studies", x = "Taxonomic Group", colour = "# Effects") + 
             theme_bw()

ggpairs(zr_data, columns = c(2,9:10), aes(colour=disp_trait), columnLabels = c("Taxa", "Correlation (r)", "Sample size (n)"))
```

We now want to convert the correlation (`corr_coeff`) to Zr instead of using the correlation (r) itself because Zr will satisfy assumptions of normality that are inherent to meta-analytic models. We can use the `escalc` function in the R package `metafor` to do that for us. Explore the help file for `escalc` and write some code to calculate Zr, and it's associated sampling variance, and add it to the data frame. Use the `var.names` argument to rename the effect size and sampling variance to "Zr" and "V_Zr". In other words, set the argument to `var.names = c("Zr", "V_Zr")`.

```{r, Zrcalc}
# Calculate Fisher's r-to-z transformed correlation coefficient (ZCOR) as yi = effect size and vi = sampling variances, where ri = raw correlation coefficients, and ni = sample size.
zr_data <- metafor::escalc(measure = "ZCOR", ri = corr_coeff, ni = sample_size, data = zr_data, var.names = c("Zr", "V_Zr"))

zr_data %>% slice_head(n = 5)
```

It's improtant to note that we can, however, convert back to the original correlation coefficient quite easily as follows:

```{r}
# We can easily convert back to r as follows
zr_data$r <- tanh(zr_data$Zr)

zr_data %>% dplyr::select(corr_coeff, r) %>% slice_head(n = 5)
```


## **Task 3: Multilevel meta-analysis**

Our data is now ready for analysis! We will use the `rma.mv` function in `metafor` to fit our first multilevel meta-analysis model. The model takes Zr as a response variable and accounts for it's sampling variance (`V` = V_Zr). 

We are also going to estimate a random effect variance for species (i.e., `species`), between study (i.e., `study_id`) and within-study (i.e., `obs`) grouping variables to control for non-independence and understand sources driving effect size variability. These are all denoted in the `random` argument of `metafor` which takes a list of all the random effects. 

You will notice that we write out the formula for the model `Zr ~ 1`. This means that we want Zr as our response variable and we only want to estimate an 'intercept' (i.e., denoted with 1) which is the overall mean estimate for Zr, our effect size. 

The full model describe above can be coded as follows:

```{r, mlmaZr, class.source='klippy'}

# Multi-level meta-analytic model
MLMA <- metafor::rma.mv(Zr ~ 1, V = V_Zr, 
                   method="REML",
                   random=list(~1|species,
                               ~1|study_ID,
                               ~1|obs), 
                   dfs = "contain",
                   test="t",
                   data=zr_data)
MLMA

```

In meta-analysis, the intercept has a lot of meaning because it provides us with an overall estimate of the effect from all experiments published in the literature. We also like to know other important aspects of the model, such as 1) how variable the effect size across studies/experiments and 2) what drives variability in effects across studies/experiments. We'll get to that shortly.

You will notice two additional arguments being specified: 

* The first, `dfs`, which calculates the degrees of freedom for the inferential tests in the model. `dfs = "contain"` will calculate the degrees of freedom based on the lowest clustering level minus 1 (in this case study). Simulations have shown that this is a more robust measure to protect against type I errors [@Nakagawa2021]. 

* The second argument, `test` specifies the test statistic used. `metafor` defaults to z values based on the standard normal distribution, however, simulations have shown [@Pappalardo2021] and it has been recommended [@Rosenberg2013b], that the t-distribution be used because samples sizes are often small and the true variance of the test is being estimated. 

